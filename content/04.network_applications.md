## Applying Knowledge Graphs to Biomedical Challenges

Knowledge graphs can be used to aid researchers in finding novel information such as new drug applications [@doi:10.7554/eLife.26726], predicting multicellular function from various tissue types [@doi:10.1093/bioinformatics/btx252] or even safe drug recommendaitons for patients [@arxiv:1710.05980].
Majority of these applications revolve around performing a network analysis task such as predicting the presence of a edge between two entites (link prediction), predicting the type of an unseen node in a network (node classification) or even suggest a group of nodes that relate to a query of interest (question and answering systems).
Initially, the first step before accomplishing the above task involves capturing and representing a network's structural information (e.g. node connectivity, edge types, node types).
This process is formally known as representation learning.
Methods within this category capture a network's structure by projecting nodes and possibly edges into a low dimensional space.
This space has numbers to represent a network's local and/or global strucutre.
We discuss various approaches used to project networks into a low dimensional space and also discuss applications that utilize this space to solve biomedical problems.

### Unifying Techniques

Mapping high dimensional data into a low dimensional space has greatly improved modeling performance in fields such as natural language processing [@arxiv:1301.3781; @arxiv:1310.4546] and image analysis [@arxiv:1512.03385].
The success of these approaches provides rationale for projecting knowledge graphs into a low dimensional space as well [@arxiv:1709.05584].
Techniques that perform this projection often require information on how nodes are connected with one another [@raw:gongreplearn; @doi:10.1109/TKDE.2016.2606098; @raw:hanreplearn; @doi:10.1145/2806416.2806512], while other approaches can work directly with the edges themselves [@arxiv:1610.04073].
We group methods for producing low-dimensional representations of knowledge graphs into the following three categories: matrix factorization, translational methods, and deep learning (Figure {@fig:unifying_techniques_overview}).

![
Pipeline for embedding knowledge graphs into a low dimensional space.
Starting with a knowledge graph, embeddings can be generated using one of the following options: Matrix Factorization (a), Translational Models (b) or Deep Learning (c).
The output of this pipeline is an embedding space that clusters similar node types together.
](images/figures/unifying_techniques_overview.png){#fig:unifying_techniques_overview}

#### Matrix Factorization

Matrix factorization is a technique that uses linear algebra to map high dimensional data into a low dimensional space.
This projection is accomplished by decomposing a matrix into a set of small rectangular matrices (Figure {@fig:unifying_techniques_overview} (a)).
Notable methods for matrix decomposition include Isomap [@doi:10.1126/science.290.5500.2319], Laplacian eigenmaps [@doi:10.1162/089976603321780317] and Principal Component Analysis (PCA) [@doi:10/bm8dnf]/Singular Vector Decomposition (SVD) [@doi:10.1007/BF02288367].
These methods were designed to be used on many different types of data; however, we discuss their use in the context of projecting knowledge graphs into a low dimensional space.	

SVD [@doi:10.1007/BF02288367] is an algorithm that uses matrix factorization to represent knowledge graphs in a low dimensional space.
The input for this algorithm is an adjacency matrix ($A$), which is a square matrix where rows and columns represent nodes and each entry represents the presence of an edge between two nodes. 
This adjacency matrix ($A$) gets decomposed into three parts: a square matrix $Σ$ and a set of two small rectangular matrices $U$ and $V^{T}$.
This values within $Σ$ are called singular values, which akin to eigenvalues [@doi:10.1007/BF02288367].
Each row in $U$ and each column in $V^{T}$ represents nodes projected onto a low dimensional space [@doi:10.1007/BF02288367; @doi:10/bm8dnf].
In practice $U$ is usually used to represent nodes in a knowledge graph, but $V^{T}$ can also be used [@doi:10.1007/BF02288367; @raw:Jiezhon2018].
Typically, SVD appears in recommendation systems via collaborative filtering [@doi:10.1155/2009/421425]; however, this technique can also be used as a standalone baseline to compare to other approaches [@arxiv:1906.05017].

Laplacian eigenmaps assume there is low dimensional structure in a high dimensional space [@doi:10.1162/089976603321780317].
This algorithm preserves this structure while projecting data into a low dimensional space. 
Typically, the first step of this algorithm is to construct a figurative knowledge graph where nodes represent datapoints and edges are constructed based on similarity of two datapoints; however, in this context, the knowledge graph has already been constructed.
The next step in this algorithm is to obtain both an adjacency matrix ($A$) and a degree matrix ($D$) from the knowledge graph.
A degree matrix is a diagonal matrix where each entry represents the number of edges connected to a node.
The adjacency and degree matrices are converted into a laplacian matrix ($L$), which is a matrix that shares the same properties as the adjacency matrix.
The laplacian matrix is generated by subtracting the adjacency matrix from the degree matrix ($L=D-A$) and, once constructed, the algorithm uses linear algebra to calculate eigenvalues and eigenvectors from the matrix ($Lx = \lambda Dx$).
The generated eigenvectors represent the knowledge graph's nodes projected onto a low dimensional space [@doi:10.1162/089976603321780317].
A number of approaches have used variants of this algorithm to perform their own node projection [@raw:gongreplearn; @doi:10.1109/TKDE.2016.2606098; @arxiv:1905.09763].
Typically, eigenmaps work well when knowledge graphs have a sparse number of edges between nodes but struggle when presented with denser networks [@arxiv:1906.05017; @doi:10.1371/journal.pcbi.1005621; @arxiv:1905.09763].
A future direction is to adapt these methods to scale to knowledge graphs that have a large number of edges.

Matrix factorization is a powerful technique that uses a matrices such as  an adjacency matrix as input.
Common approaches involve using SVD, Laplacian eigenmaps or variants of the two to perform embeddings.
Despite reported success, the dependence on matrices like an adjacency matrix creates an issue of scalability as matrices of large networks would take too much memory for a regular computer to handle.
Furthermore, these methods treat all edge types the same, but a possible extension for future approaches that use matrix factorization would be to incorporate node and edge types as sources of input.

#### Translational Distance Models

Translational distance models treat edges in a knowledge graph as linear transformations.
As an example, one such algorithm, TransE [@raw:bordestranse], treats every node-edge pair as a triplet with head nodes represented as $\textbf{h}$, edges represented as $\textbf{r}$, and tail nodes represented as $\textbf{t}$.
These representations are combined into an equation that mimics the iconic word vectors translations ($\textbf{king} - \textbf{man} + \textbf{woman} \approx \textbf{queen}$) from the Word2vec model [@arxiv:1310.4546].
The equation is shown as follows: $\textbf{h} + \textbf{r} \approx \textbf{t}$.
Starting at the head node ($\textbf{h}$), add the edge vector ($\textbf{r}$) and the result should be the tail node ($\textbf{t}$).
TransE optimizes embeddings for $\textbf{h}$, $\textbf{r}$, $\textbf{t}$, while guaranteeing the global equation ($\textbf{h} + \textbf{r} \approx \textbf{t}$) is satisfied [@raw:bordestranse].
A caveat to the TransE approach is that it the training steps force relationships to have a one to one mapping, which may not be appropriate for all types of relationships.

Wang et al. [@raw:wangtransH] attempted to resolve the one to one mapping issue by developing the TransH model.
TransH treats relations as hyperplanes rather than a regular vector and projects the head ($\textbf{h}$) and tail ($\textbf{t}$) nodes onto the hyperplane.
Following this projection, a distance vector ($\textbf{d}_{r}$) is calculated between the projected head and tail nodes.
Finally, each vector is optimized while preserving the global equation ($\textbf{h} + \textbf{d}_{r} \approx \textbf{t}$) [@raw:wangtransH].
Other approaches [@raw:lintransR, @arxiv:1610.04073; @arxiv:1909.00672] have built off of the TransE and TransH models. 
In the future, it may be beneficial for these models is to incorporate other types of information such as edge confidence scores, textual information, or edge type information when optimizing these embeddings.

#### Deep Learning

Deep learning is a paradigm that uses multiple non-linear transformations to map high dimensional data into a low dimensional space.
Many techniques that use deep learning for knowledge graphs are based on word2vec [@arxiv:1310.4546; @arxiv:1301.3781], a set of approaches that are widely used for natural language processing.
The goal of word2vec is to project words into a low dimensional space that preserves their semantic meaning.
Strategies for training word2vec models use one of two neural network architectures: skip-gram and continuous bag of words (CBOW).
Both models are feed-forward neural networks, but CBOW models are trained to predict a word given it's context while skip-gram models are trained to predict the context given a word [@arxiv:1310.4546; @arxiv:1301.3781].
Once training has finished, words are now associated with dense vectors that downstream models, such as feed forward networks or recurrent networks, can use for input.

Deepwalk [@arxiv:1403.6652] is an early method designed to project a knowledge graph into a low dimensional space. 
The first step of this method is to perform a random walk along a knowledge graph.
During the random walk, every generated sequence of nodes is recorded and treated like a sentence in word2vec [@arxiv:1310.4546; @arxiv:1301.3781].
After every node has been processed, a skip-gram model is trained to predict the context of each node thereby projecting a knowledge graph into a low dimensional space [@arxiv:1403.6652].
A limitation of this method is that the random walk cannot be controlled, so every node has an equal chance to be reached.
Grover and Leskovec [@arxiv:1607.00653] demonstrated that this limitation can hurt performance when classifying edges between nodes and developed node2vec as a result.
Node2vec [@arxiv:1607.00653] operates the in the same fashion as deepwalk; however, this algorithm specifies a parameter that lets the random walk be biased when traversing nodes.
A caveat to both deepwalk and node2vec is that both algorithms ignore information such as edge type and node type.
Various approaches have evolved to fix this limitation by incorporating  node, edge and even path types when projecting nodes into a low dimensional space [@arxiv:1704.03165; @doi:10.1145/3097983.3098036; @arxiv:1809.02269; @arxiv:1808.05611].
These approaches primarily capture a network's local structure. 
An emerging area of work is to develop approaches that capture both the local and global structure of a network when projecting knowledge graphs into a low dimensional space.

Some deep learning approaches use an adjacency matrix as input [@arxiv:1310.4546; @arxiv:1301.3781] instead of using the word2vec framing.
Algorithms such as auto-encoders can also generate network embeddings [@arxiv:1802.08352; @arxiv:1611.07308; @arxiv:1802.04407].
Autoencoders [@arxiv:1404.7828; @raw:Baldi2011] are neural networks that map input such as an adjacency matrices into a low dimensional space and then learns how to construct this space by reconstructing the same input.
The generated low dimensional space captures the node connectivity structure of the knowledge graph and every node is mapped onto this space [@arxiv:1802.08352; @arxiv:1611.07308; @arxiv:1802.04407].
Despite the high potential of this approach, this method relies on an adjacency matrix for input.
If a knowledge graph asymptotically increases in size, these approaches could run into scalability issues as discovered by Khosla et al. [@arxiv:1903.07902].
Plus, Khosla et al.[@arxiv:1903.07902] discovered that approaches akin to node2vec outperformed algorithms using autoencoders when undergoing link prediction and node classification.
Overall, the performance of these models largely depends upon the structure of nodes and edges within a knowledge graph [@arxiv:1903.07902].
Future approaches should consider creating hybrid models that use both node2vec and autoencoders to construct complementary low dimensional representations of knowledge graphs.

### Unifying Applications

Knowledge graphs have been used in many biomedical applications ranging from identifying protein functions [@doi:10.1186/s12859-018-2163-9] to prioritizing cancer genes [@doi:10.1093/bioinformatics/bty148] to recommending safer drugs to patients [@arxiv:1710.05980; @doi:10.1609/aaai.v33i01.33011126] (Figure {@fig:unifying_applications}).
In this section we discuss how knowledge graphs are being applied in biomedical settings. 
We put particular emphasis on an emerging set of techniques: those that project knowledge graphs into a low dimensional space.

![
Overview of biomedical applications that make use of knowledge graphs.
Categories consist of: (a) Multi-Omic applications, (b) Pharmaceutical Applications and (c) Clinical Applications.
](images/figures/unifying_applications_overview.png){#fig:unifying_applications}

#### Multi-Omic Applications

Multi-omic applications for knowledge graphs include efforts to study the genome, how genes are expressed in the transcriptome, and how the products of those transcripts interact in the proteome.
Approaches in this category use knowledge graphs to establish connections between -omic entities as well as diseases.
Such tasks include gene-symptom prioritization [@doi:10.1093/jamia/ocy117], protein-protein interaction prediction [@doi:10.1089/cmb.2012.0273;10.1186/1752-0509-9-S1-S9], and detecting miRNA-disease associations [@doi:10.1155/2017/2498957].
We focus specifically on multi-omic applications of algorithms that project knowledge graphs into a low dimensional space to make connections.

Knowledge graphs have been used as recommendation systems to establish links between RNA with disease and proteins with other proteins.
Shen et al. [@doi:10.1155/2017/2498957] used an algorithm called collaborative filtering to establish an association between miRNA and diseases.
The authors constructed an miRNA-Disease network using the HMDDD database [@doi:10.1093/nar/gky1010] and generated an adjacency matrix with the rows representing miRNA and the columns representing diseases.
This adjacency matrix was decomposed into small rectangular matrices using SVD, then these matricies were used to calculate similarity scores between the miRNA and diseases.
High scores implied a high likelihood that a given miRNA had an association with a given disease [@doi:10.1155/2017/2498957].
Other approaches have built off of Shen et al.'s [@doi:10.1155/2017/2498957] work by incorpoating novel ways to perform matrix factorization [@doi:10.3390/genes10020080; @doi:10.1186/s12859-019-2956-5;@doi:10.1186/s12859-019-3260-0] or by integrating machine learning models in conjunction with matrix factorization [@doi:10.1109/TCBB.2019.2937774].
These methods provided high AUROCs, but new discoveries have been hard to validate as experiments in this space are costly and time consuming at best [@doi:10.1155/2017/2498957].
Apart from miRNA, collaborative filtering has been used to predict protein-protein interactions [@doi:10.1109/BIBM.2010.5706537; @doi:10.1089/cmb.2012.0273; @doi:10.1186/1752-0509-9-S1-S9].
Though extensive validation of newly generated candidates may be impractical, it would be helpful to see future efforts in this space include a blinded literature search for prioritized and randomly selected candidates as part of the standard evaluation of such approaches.

Approaches that use deep learning have mainly used the node2vec model [@arxiv:1607.00653] or variants of that model.
Yang et al. [@doi:10.1093/jamia/ocy117] used node2vec to create a recommendation system to infer associations between genes and disease symptoms.
The authors constructed a gene-disease symptom knowledge graph by combining two bipartite graphs: genes-diseases and diseases-disease symptoms.
The generated knowledge graph was embedded via node2vec and similarity scores were calculated for every gene-symptom pair in the graph.
High scores implicated high chance for an association [@doi:10.1093/jamia/ocy117].
This approach outperformed methods that didn't use a knowledge graph; however, validation was difficult as it involved manual curation of the literature @doi:10.1093/jamia/ocy117].
Similar approaches used variants of the node2vec algorithm to predict gene-disease associations
[@doi:10.1093/bioinformatics/bty559; doi:10.3389/fgene.2019.00226 @doi:10.1186/s12920-019-0627-z; @doi:10.1109/BIBM47256.2019.8983134] analyze RNA-seq data [@doi:10.1093/nar/gkx750] and infer novel protein information [@doi:10.1093/bioinformatics/btx275; @doi:10.1007/978-3-030-00825-3_16; @doi:10.1016/j.artmed.2019.04.001; @doi:10.1186/s12859-018-2163-9].
Future extensions of these applications should consider incorporating more sources of data such as compounds, anatomic locations or even gene pathways to improve prediciton performance.

Knowledge graphs have aided the multi-omics field by generating novel discoveries.
Most approaches to date use matrix factorization and node2vec to project knowledge graph into a low dimensional space, and translational models may be an untapped resource that could aid future efforts.
Another area of exploration could be the incorporation of multiple sources of information such as anatomic locations or genetic pathways to improve the specificity of findings (i.e., to predict that a protein-protein interaction happens in a specific cell type or tissue).

#### Pharmaceutical Applications

There are many examples of how knowledge graphs are applied to identify new properties of drugs.
Tasks in this context involve prediction drugs interacting with other drugs [@doi:10.1016/j.websem.2017.06.002], identifying molecular targets a drug might interact with [@doi:10.1155/2015/275045] and identifying new disease treatments for previously established drugs [@doi:10.7554/eLife.26726.001].
As with other applications, we focus on those that use low-dimensional representations.

Similar to multi-omic applications knowledge graphs have been used in recommendation systems to infer novel links between drugs and diseases.
Dai et al. [@doi:10.1155/2015/275045] used collaborative filtering to infer drug-disease associations.
The authors constructed a drug-disease network by integrating two bipartite networks: a drug-gene interaction network and a disease-gene interaction network.
They integrated both networks under the assumption that drugs associated with a disease interact with the same gene of interest. 
Then the authors generated an adjacency matrix where rows represent drugs and columns represent diseases and decomposed this matrix into two small rectangular matrices. 
These matrices were used to calculate similarity scores between all drugs and all diseases where high values implicate an association [@doi:10.1155/2015/275045].
Related approaches have been used to infer drug-target interactions [@doi:10.1109/TCBB.2016.2530062; @doi:10.1109/BIOCAS.2018.8584817; @doi:10.1093/bioinformatics/btaa010] and drug-disease treatments [@doi:10.1109/TCBB.2018.2830384; @doi:10.1371/journal.pcbi.1004760; @doi:10.1038/srep40376; @doi:10.1021/ci500340n; @doi:10.1186/s12859-018-2220-4]
In spite of reported success, these approaches are limited to the drugs and diseases contained in the network.
Combining these approaches with representations of chemical structures might make it possible to one day make predictions about novel compounds.

Deep learning applications have used node2vec [@doi:10.1093/bioinformatics/btx160; @doi:10.1101/539643] and auto-encoder [@arxiv:1804.10850v1; @arxiv:1802.00543] approaches to project knowledge graphs into a low dimensional space.
Zong et al. [@doi:10.1093/bioinformatics/btx160] used a node2vec-like model to predict drug-target associations.
The authors constructed a disease-target-disease network using drug centered databases: Drugbank [@doi:10.1093/nar/gkm958] and Diseasome [@doi:10.1073/pnas.0701361104].
Next, the authors applied a random walk to the network and trained a skip-gram model to generate node embeddings.
Lastly, the authors constructed a similarity metric to rank how similar drugs are to their targets [@doi:10.1093/bioinformatics/btx160].
A limitation to this method is that their network is missing information such as pharmacological class or drug chemical structure that may help in prediction performance.
Overall, deep learning provides a robust set of techniques that has been shown to outperform most linear approaches in this context [@doi:10.1186/s12859-019-3284-5; @doi:10.1145/3307339.3342161].

Knowledge graphs can support drug discovery efforts by predicting drug information such as drug side effects and new disease treatments.
Most methods to date use matrix factorization and deep learning techniques to produce a low-dimensional representation.
Due to the success of deep learning [@doi:10.1186/s12859-019-3284-5; @doi:10.1145/3307339.3342161] the focus of the field has shifted to these techniques; however, a possible extension is to use an ensemble of deep learning techniques and linear methods to improve performance.
Plus, another area of exploration is to incorporate information such as phamaceutical classes for drugs or chemical structure to improve knowledge graph detection power.

#### Clinical applications

Using knowledge graphs for clinical applications is in early stages of development, but the long-term goal is to use analyses of knowledge graphs to aid patient care.
Typically, graphs for these applications are constructed from electronic health records (EHR) and nodes represent patients, drugs and diseases and edges represent relationships such as a patient being prescribed a treatment or a patient being diagnosed with a disease [@pmid:26306276; @doi:10.1145/2110363.2110415; @arxiv:1707.05340; @doi:10.1186/s12859-015-0549-5].
Tasks range from improving patient diagnoses [@doi:10.1109/TKDE.2016.2605687;@arxiv:1709.06908] to recommending safer drugs for patients [@arxiv:1710.05980; @arxiv:1709.06908].

Early work in this field applied translational models (Figure {@fig:unifying_techniques_overview} (b)) to knowledge graphs to recommend safe drugs.
Wang et al. [@arxiv:1710.05980] used a variant of the TransH [@raw:wangtransH] model to create such a system for patients.
They constructed a disease-patient-drug network by integrating a patient-disease bipartite network with a patient-drug bipartite network.
Every node in the graph was embedded while satisfying the following equation: $\textbf{h} - r \approx \textbf{t}$.
Following the embedding step, the authors formulated their own similarity metric that selected drug combinations with a low number of interactions [@arxiv:1710.05980].
Researchers in [@arxiv:1909.00672] applied a similar variant of the TransH model to a medical knowledge graph and evaluated their model for link prediction rather than patient recommendation.

In contrast with other applications where node2vec and auto-encoder models have become established, deep learning methods in this area often use graph attention models [@arxiv:1706.03762].
These models mimic machine translation models [@arxiv:1409.0473] and aim to simultaneously embed knowledge graphs into a low dimensional space and perform the task at hand.
Choi et al. [@arxiv:1611.07012] used a graph attention model to predict patient diagnoses.
The authors constructed a directed graph using medical concepts from patient EHR data.
This directed graph was fed into a graph attention network and then used to predict a patient's likelihood of heart failure [@arxiv:1611.07012].
Other approaches have used graph attention models to perform clinical tasks such as drug safety recommendations [@doi:10.1609/aaai.v33i01.33011126] and patient diagnoses [@arxiv:1906.04716].

Knowledge graphs have shown promising results when used for clinical applications; however, there is still room for improvement.
Most approaches have run into the common problem with missing data from EHR [@arxiv:1611.07012; @arxiv:1710.05980; @doi:10.1609/aaai.v33i01.33011126].
Future directions consist of designing algorithms that can fill in this missing data gap or construct models that can take missing data into account.
